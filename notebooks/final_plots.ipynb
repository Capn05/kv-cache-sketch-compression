{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final plots (GPT-2, A100)\n",
        "\n",
        "This notebook generates the plots used in the final `PROJECT.md` writeup:\n",
        "- Baseline full-cache metrics at total lengths 256 and 512\n",
        "- Baseline comparisons (sliding window, quantization)\n",
        "- CMS eviction runs (targeted 12-config grid)\n",
        "\n",
        "Outputs are saved under `results/figures/`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "ROOT = Path(\"..\")\n",
        "RESULTS = ROOT / \"results\"\n",
        "FIG_DIR = RESULTS / \"figures\"\n",
        "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "BASELINE_SUMMARY = RESULTS / \"baseline\" / \"baseline_summary.json\"\n",
        "BASELINES_COMPARISON = RESULTS / \"baselines\" / \"comparison_summary.json\"\n",
        "SKETCH_TARGETED = RESULTS / \"sketch\" / \"targeted_summary.json\"\n",
        "\n",
        "print(\"baseline:\", BASELINE_SUMMARY.exists())\n",
        "print(\"baselines comparison:\", BASELINES_COMPARISON.exists())\n",
        "print(\"sketch targeted:\", SKETCH_TARGETED.exists())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_json(path: Path):\n",
        "    with path.open(\"r\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "baseline = read_json(BASELINE_SUMMARY)\n",
        "comparison = read_json(BASELINES_COMPARISON)\n",
        "\n",
        "baseline_df = pd.DataFrame(\n",
        "    [\n",
        "        {\n",
        "            \"total_length\": 256,\n",
        "            \"memory_mb\": baseline[\"memory_mb_seq256_mean\"],\n",
        "            \"latency_ms_per_token\": baseline[\"latency_ms_seq256_mean\"],\n",
        "            \"tokens_per_sec\": baseline[\"tokens_per_sec_seq256_mean\"],\n",
        "        },\n",
        "        {\n",
        "            \"total_length\": 512,\n",
        "            \"memory_mb\": baseline[\"memory_mb_seq512_mean\"],\n",
        "            \"latency_ms_per_token\": baseline[\"latency_ms_seq512_mean\"],\n",
        "            \"tokens_per_sec\": baseline[\"tokens_per_sec_seq512_mean\"],\n",
        "        },\n",
        "    ]\n",
        ")\n",
        "\n",
        "rows = []\n",
        "for bucket, data in comparison[\"results\"].items():\n",
        "    total_length = int(bucket.replace(\"len\", \"\"))\n",
        "    for method, stats in data.items():\n",
        "        rows.append(\n",
        "            {\n",
        "                \"total_length\": total_length,\n",
        "                \"method\": method,\n",
        "                \"memory_mb\": stats.get(\"avg_memory_mb\"),\n",
        "                \"latency_s\": stats.get(\"avg_latency_s\"),\n",
        "            }\n",
        "        )\n",
        "comparison_df = pd.DataFrame(rows)\n",
        "\n",
        "baseline_df, comparison_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot baseline vs baselines-comparison latency (total wall time)\n",
        "plt.figure(figsize=(7, 4))\n",
        "plot_df = comparison_df.copy()\n",
        "plot_df[\"latency_s\"] = plot_df[\"latency_s\"].astype(float)\n",
        "\n",
        "sns.barplot(data=plot_df, x=\"total_length\", y=\"latency_s\", hue=\"method\")\n",
        "plt.title(\"Baseline comparisons: wall-time latency\")\n",
        "plt.ylabel(\"seconds (avg per sample)\")\n",
        "plt.xlabel(\"total length\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_DIR / \"baselines_comparison_latency.png\", dpi=200)\n",
        "plt.show()\n",
        "\n",
        "# Plot baseline throughput\n",
        "plt.figure(figsize=(7, 4))\n",
        "sns.barplot(data=baseline_df, x=\"total_length\", y=\"tokens_per_sec\")\n",
        "plt.title(\"Full-cache baseline throughput\")\n",
        "plt.ylabel(\"tokens/sec\")\n",
        "plt.xlabel(\"total length\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_DIR / \"baseline_throughput.png\", dpi=200)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load sketch targeted summary (generated by experiments/sketch_experiments.py --grid targeted)\n",
        "sketch = read_json(SKETCH_TARGETED)\n",
        "\n",
        "sk_rows = []\n",
        "for r in sketch[\"results\"]:\n",
        "    cfg = r[\"config\"]\n",
        "    sk_rows.append(\n",
        "        {\n",
        "            \"total_length\": r[\"total_length\"],\n",
        "            \"sketch_width\": cfg[\"sketch_width\"],\n",
        "            \"sketch_depth\": cfg[\"sketch_depth\"],\n",
        "            \"max_cache_size\": cfg[\"max_cache_size\"],\n",
        "            \"avg_memory_mb\": r[\"avg_memory_mb\"],\n",
        "            \"cache_memory_mb\": r[\"cache_memory_mb\"],\n",
        "            \"sketch_memory_mb\": r[\"sketch_memory_mb\"],\n",
        "            \"avg_latency_s\": r[\"avg_latency_s\"],\n",
        "            \"avg_throughput\": r[\"avg_throughput\"],\n",
        "        }\n",
        "    )\n",
        "\n",
        "sketch_df = pd.DataFrame(sk_rows)\n",
        "sketch_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cache size vs max_cache_size\n",
        "plt.figure(figsize=(7, 4))\n",
        "sns.lineplot(data=sketch_df, x=\"max_cache_size\", y=\"cache_memory_mb\", hue=\"total_length\", marker=\"o\")\n",
        "plt.title(\"Sketch eviction: cache MB vs max_cache_size\")\n",
        "plt.ylabel(\"cache MB (all layers)\")\n",
        "plt.xlabel(\"max_cache_size (tokens)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_DIR / \"sketch_cache_mb_vs_max_cache_size.png\", dpi=200)\n",
        "plt.show()\n",
        "\n",
        "# Throughput vs max_cache_size\n",
        "plt.figure(figsize=(7, 4))\n",
        "sns.lineplot(data=sketch_df, x=\"max_cache_size\", y=\"avg_throughput\", hue=\"total_length\", marker=\"o\")\n",
        "plt.title(\"Sketch eviction: throughput vs max_cache_size\")\n",
        "plt.ylabel(\"tokens/sec\")\n",
        "plt.xlabel(\"max_cache_size (tokens)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_DIR / \"sketch_throughput_vs_max_cache_size.png\", dpi=200)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
